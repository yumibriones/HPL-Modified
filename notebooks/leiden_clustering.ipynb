{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Leiden Clustering ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 15:12:51.435663: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745953971.461996 2977506 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745953971.471030 2977506 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-29 15:12:51.503026: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import umap\n",
    "import math\n",
    "import os\n",
    "import scanpy as sc\n",
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def load_data(metadata_file, embedding_file, filenames_file):\n",
    "    \"\"\"\n",
    "    Load metadata, embeddings, and filenames and merge them based on filepaths.\n",
    "    \n",
    "    Parameters:\n",
    "    - metadata_file: Path to the CSV file containing metadata.\n",
    "    - embedding_file: Path to the .npy file containing the embeddings.\n",
    "    - filenames_file: Path to the .npy file containing the corresponding filenames.\n",
    "    \n",
    "    Returns:\n",
    "    - Merged DataFrame with embeddings and metadata.\n",
    "    \"\"\"\n",
    "    print(\"Loading metadata and embeddings...\")\n",
    "    # Load metadata\n",
    "    metadata = pd.read_csv(metadata_file)\n",
    "    metadata['filepath'] = metadata.apply(\n",
    "        lambda row: f\"/gpfs/scratch/yb2612/dl4med_25/dl_project/data/scratch_data/{row['original_set']}/{row['slides']}/{row['tiles']}\",\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Replace 'valid' with 'val' in the 'filepath' column\n",
    "    metadata['filepath'] = metadata['filepath'].str.replace('valid', 'val')\n",
    "\n",
    "    # Load embeddings and filenames\n",
    "    embeddings = np.load(embedding_file, allow_pickle=True)\n",
    "    filepaths = np.load(filenames_file, allow_pickle=True)\n",
    "\n",
    "    # Convert embeddings to a DataFrame\n",
    "    img_z_latent = [emb for emb in embeddings]\n",
    "    embedding_df = pd.DataFrame({\n",
    "        \"filepath\": filepaths,\n",
    "        \"img_z_latent\": img_z_latent\n",
    "    })\n",
    "    \n",
    "    # Merge embeddings with metadata\n",
    "    merged_df = metadata.merge(embedding_df, on=\"filepath\", how=\"inner\")\n",
    "    return merged_df\n",
    "\n",
    "def run_umap(merged_df, n_neighbors=30, min_dist=0.0, n_components=2, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform UMAP transformation on the img_z_latent column of the merged dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - merged_df: DataFrame with the img_z_latent column.\n",
    "    - n_neighbors, min_dist, n_components, random_state: UMAP hyperparameters.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with UMAP results added.\n",
    "    \"\"\"\n",
    "    # Clean 'img_z_latent' column\n",
    "    merged_df['img_z_latent'] = merged_df['img_z_latent'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    img_z_latent = pd.DataFrame(merged_df['img_z_latent'].to_list())\n",
    "\n",
    "    # Perform UMAP\n",
    "    print(\"Running UMAP...\")\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=random_state, low_memory=True)\n",
    "    umap_result = umap_model.fit_transform(img_z_latent)\n",
    "\n",
    "    # Add UMAP results to DataFrame\n",
    "    merged_df['umap_1'] = umap_result[:, 0]\n",
    "    merged_df['umap_2'] = umap_result[:, 1]\n",
    "    \n",
    "    return merged_df\n",
    "    \n",
    "def run_leiden(merged_df, resolution=2.0):\n",
    "    \"\"\"\n",
    "    Run Leiden clustering using Scanpy on img_z_latent and append the labels to the dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - merged_df: DataFrame with the img_z_latent column.\n",
    "    - resolution: Resolution parameter for the Leiden algorithm.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with a new column 'leiden_{resolution}' for clustering labels.\n",
    "    \"\"\"\n",
    "    print(\"Running Leiden clustering...\")\n",
    "    \n",
    "    # Prepare latent embedding matrix\n",
    "    merged_df['img_z_latent'] = merged_df['img_z_latent'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    X = np.vstack(merged_df['img_z_latent'].to_numpy())\n",
    "\n",
    "    # Create AnnData object\n",
    "    adata = ad.AnnData(X)\n",
    "\n",
    "    # Build neighborhood graph\n",
    "    sc.pp.neighbors(adata, use_rep='X', n_neighbors=250, method='umap')\n",
    "\n",
    "    # Run Leiden clustering\n",
    "    sc.tl.leiden(adata, resolution=resolution, key_added=f'leiden_{resolution}')\n",
    "\n",
    "    # Append clustering labels to original dataframe\n",
    "    merged_df[f'leiden_{resolution}'] = adata.obs[f'leiden_{resolution}'].values\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing VICReg_5/test data...\n",
      "Loading metadata and embeddings...\n",
      "Running UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/scratch/mottej02/conda/dl/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/gpfs/scratch/mottej02/conda/dl/lib/python3.9/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Leiden clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2977506/3898342496.py:90: FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg.\n",
      "\n",
      " To achieve the future defaults please pass: flavor=\"igraph\" and n_iterations=2.  directed must also be False to work with igraph's implementation.\n",
      "  sc.tl.leiden(adata, resolution=resolution, key_added=f'leiden_{resolution}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved UMAP + Leiden results to /gpfs/data/pmedlab/Users/mottej02/dl_project/pipeline/Histomorphological-Phenotype-Learning/results/VICReg_5/epoch_20/dataframes/test/leiden/umap_leiden_results.csv\n"
     ]
    }
   ],
   "source": [
    "# USAGE\n",
    "metadata_file = \"/gpfs/scratch/yb2612/dl4med_25/dl_project/scratch_data/hpl-clip/lung_subsample_clinical_clusters.csv\"\n",
    "\n",
    "epoch = 27\n",
    "\n",
    "for model in [\"BarlowTwins_3\"]:\n",
    "    for set in [\"test\"]:\n",
    "        print(f\"Processing {model}/{set} data...\")\n",
    "        embedding_file = f\"/gpfs/data/pmedlab/Users/mottej02/dl_project/pipeline/Histomorphological-Phenotype-Learning/results/{model}/epoch_{epoch}/dataframes/{set}/image_embeddings.npy\"\n",
    "        filenames_file = f\"/gpfs/data/pmedlab/Users/mottej02/dl_project/pipeline/Histomorphological-Phenotype-Learning/results/{model}/epoch_{epoch}/dataframes/{set}/image_filenames.npy\"\n",
    "        save_dir = f\"/gpfs/data/pmedlab/Users/mottej02/dl_project/pipeline/Histomorphological-Phenotype-Learning/results/{model}/epoch_{epoch}/dataframes/{set}/leiden\"\n",
    "\n",
    "        merged_df = load_data(metadata_file, embedding_file, filenames_file)\n",
    "        merged_df = run_umap(merged_df)\n",
    "        merged_df = run_leiden(merged_df)\n",
    "\n",
    "        # Save the dataframe\n",
    "        output_file = os.path.join(save_dir, \"umap_leiden_results.csv\")\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved UMAP + Leiden results to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
